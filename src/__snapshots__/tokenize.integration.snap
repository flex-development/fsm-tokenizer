// Vitest Snapshot v1, https://vitest.dev/guide/snapshot.html

exports[`integration:tokenize > default constructs > should tokenize empty file 1`] = `
tokens[2]
├─0 sof (1:1-1:1, 0-0)
└─1 eof (1:1-1:1, 0-0)
`;

exports[`integration:tokenize > default constructs > should tokenize non-empty file 1`] = `
tokens[2]
├─0 sof (1:1-1:1, 0-0)
└─1 eof (22:1-22:1, 304-304)
`;

exports[`integration:tokenize > user constructs > non-empty file > sample 0 1`] = `
tokens[3]
├─0 sof (1:1-1:1, 0-0)
├─1 inlineTag (1:1-1:17, 0-16)
└─2 eof (2:1-2:1, 17-17)
`;

exports[`integration:tokenize > user constructs > non-empty file > sample 1 1`] = `
tokens[13]
├─0  sof (1:1-1:1, 0-0)
├─1  punctuator "=" (1:10-1:11, 9-10)
├─2  string "\\"hello 👋\\"" (1:12-1:21, 11-20)
├─3  punctuator ";" (1:21-1:22, 20-21)
├─4  punctuator "." (2:8-2:9, 29-30)
├─5  punctuator "(" (2:12-2:13, 33-34)
├─6  punctuator "\\\\" (2:13-2:14, 34-35)
├─7  punctuator "\\\\" (2:19-2:20, 40-41)
├─8  punctuator ")" (2:25-2:26, 46-47)
├─9  punctuator ";" (2:26-2:27, 47-48)
├─10 punctuator "/" (2:28-2:29, 49-50)
├─11 punctuator "/" (2:29-2:30, 50-51)
└─12 eof (3:1-3:1, 60-60)
`;

exports[`integration:tokenize > user constructs > non-empty file > sample 2 1`] = `
tokens[8]
├─0 sof (1:1-1:1, 0-0)
├─1 string "'😍'" (1:1-1:4, 0-3)
├─2 string "\\"👍\\"" (2:1-2:4, 4-7)
├─3 punctuator "\\\\" (3:1-3:2, 8-9)
├─4 punctuator "'" (3:2-3:3, 9-10)
├─5 punctuator "\\\\" (3:4-3:5, 11-12)
├─6 punctuator "'" (3:5-3:6, 12-13)
└─7 eof (4:1-4:1, 14-14)
`;

exports[`integration:tokenize > user constructs > non-empty file > sample 3 1`] = `
tokens[42]
├─0  sof (1:1-1:1, 0-0)
├─1  number "0" (1:1-1:2, 0-1)
├─2  whitespace "\\n" (1:2-2:1, 1-2)
├─3  bigint "0n" (2:1-2:3, 2-4)
├─4  whitespace "\\n" (2:3-3:1, 4-5)
├─5  number "1" (3:1-3:2, 5-6)
├─6  whitespace "\\n" (3:2-4:1, 6-7)
├─7  bigint "1n" (4:1-4:3, 7-9)
├─8  whitespace "\\n" (4:3-5:1, 9-10)
├─9  number "2" (5:1-5:2, 10-11)
├─10 whitespace "\\n" (5:2-6:1, 11-12)
├─11 bigint "2n" (6:1-6:3, 12-14)
├─12 whitespace "\\n" (6:3-7:1, 14-15)
├─13 number "3" (7:1-7:2, 15-16)
├─14 whitespace "\\n" (7:2-8:1, 16-17)
├─15 bigint "3n" (8:1-8:3, 17-19)
├─16 whitespace "\\n" (8:3-9:1, 19-20)
├─17 number "4" (9:1-9:2, 20-21)
├─18 whitespace "\\n" (9:2-10:1, 21-22)
├─19 bigint "4n" (10:1-10:3, 22-24)
├─20 whitespace "\\n" (10:3-11:1, 24-25)
├─21 number "5" (11:1-11:2, 25-26)
├─22 whitespace "\\n" (11:2-12:1, 26-27)
├─23 bigint "5n" (12:1-12:3, 27-29)
├─24 whitespace "\\n" (12:3-13:1, 29-30)
├─25 number "6" (13:1-13:2, 30-31)
├─26 whitespace "\\n" (13:2-14:1, 31-32)
├─27 bigint "6n" (14:1-14:3, 32-34)
├─28 whitespace "\\n" (14:3-15:1, 34-35)
├─29 number "7" (15:1-15:2, 35-36)
├─30 whitespace "\\n" (15:2-16:1, 36-37)
├─31 bigint "7n" (16:1-16:3, 37-39)
├─32 whitespace "\\n" (16:3-17:1, 39-40)
├─33 number "8" (17:1-17:2, 40-41)
├─34 whitespace "\\n" (17:2-18:1, 41-42)
├─35 bigint "8n" (18:1-18:3, 42-44)
├─36 whitespace "\\n" (18:3-19:1, 44-45)
├─37 number "9" (19:1-19:2, 45-46)
├─38 whitespace "\\n" (19:2-20:1, 46-47)
├─39 bigint "9n" (20:1-20:3, 47-49)
├─40 whitespace "\\n" (20:3-21:1, 49-50)
└─41 eof (21:1-21:1, 50-50)
`;

exports[`integration:tokenize > user constructs > should tokenize empty file 1`] = `
tokens[2]
├─0 sof (1:1-1:1, 0-0)
└─1 eof (1:1-1:1, 0-0)
`;
